{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Methane-hackathon","text":"<p>A methane detection project using satellite images</p> <p>-&gt; View the documentation on Github Pages</p>"},{"location":"#requirements","title":"Requirements","text":""},{"location":"#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.9 or higher</li> </ul>"},{"location":"#packages","title":"Packages","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"#structure","title":"Structure","text":"<p>The structure of the repository is as follows : </p> <pre><code>methane-hackathon\n\u2523 app/ --&gt; hosts the streamlit webapp\n\u2523 data/ --&gt; for all data files during development\n\u2503 \u2523 interim/\n\u2503 \u2523 processed/\n\u2503 \u2517 raw/\n\u2523 docs/ --&gt; includes docs file (where index.md is a copy of the readme)\n\u2523 logs/ --&gt; stores models &amp; results \n\u2523 models/ --&gt; store models \n\u2523 notebooks/ --&gt; for exploration and trial\n\u2523 output/ --&gt; submission file\n\u2523 tests/ --&gt; for smooth CI/CD\n\u2523 utils/ --&gt; useful misc scripts\n\u2523 .gitignore\n\u2523 mkdocs.yml\n\u2523 README.md\n\u2517 requirements.txt \n</code></pre>"},{"location":"#running-the-project","title":"Running the project","text":"<p>To navigate the project, we suggest :</p> <ul> <li> <p>View the documentation on https:// ... -&gt; Alternatively, you can run 'mkdocs serve' in your terminal to have a local host</p> </li> <li> <p>Run the app with <code>streamlit run app/streamlit-app.py</code>  (for a more extensive description, see the documentation)</p> </li> <li> <p>See model specification in the \"model\" section of the documentation</p> </li> </ul>"},{"location":"app_doc/","title":"Streamlit App","text":"<p>The following page introduces the streamlit app and its basic functions</p> <p>You can run the app with <code>streamlit run app/streamlit-app.py</code> in your terminal.</p>"},{"location":"app_doc/#description","title":"Description","text":"<p>The app is divided in three portals :</p>"},{"location":"app_doc/#methane-detection","title":"Methane detection","text":"<p>The goal of this display is to detect the presence of methane in a satellite image. The user can either use one of the demo images, or upload a .tif image of his choice. </p> <p>Different models are available for comparison, and a heatmap can also be shown over the image to highlight the most important datapoints - i.e. the plume, in the case of presence of methane.</p>"},{"location":"app_doc/#metadata-analysis","title":"Metadata analysis","text":"<p>This page provides an analysis of already available data on methane leakages in various areas. It has two main parts:</p> <p>1/ A map showing where available images are located, with a red dot for methane leakages and a green one for clean areas</p> <p>2/ A deep-dive of each location available, with its coordinates, methane detection history and appropriate dataframe. It also gives the possibility to explore new locations given coordinate points.</p>"},{"location":"app_doc/#cleanr-workspace","title":"CleanR workspace","text":"<p>This dashboard is meant to be used by CleanR only. </p> <p>For each location available - or any new location of your choice -, it will provide the company with potential customers and partners in the area, to work together on solving methane-related issues.</p>"},{"location":"model_training/","title":"Directory to store bash-scripts to execute pytorch training pipelines.","text":"<p>From the root directory: 1. First, you need to make bash-script executable: <code>chmod u+x ./bash/convnext-base-train.sh</code> 2. Execute: <code>./bash/convnext-base-train.sh</code></p>"},{"location":"model_training/#training-keras-models-from-the-terminal","title":"Training Keras models from the Terminal","text":"<ul> <li>From the main directory, run: <code>python training_pipelines/train_keras.py &lt;name of the model&gt;</code> from the command line interface.</li> <li>You may change the validation set size, n_epochs and many more parameters from the command line. Example: <code>python training_pipelines/train_keras.py model_name --val_size 0.2 --epochs 10 --batch_size 32 --group_split --augment --aug_batch 32</code></li> <li>Running this model will create a log file to track the progress and see previous model runs. To access the log files and check the details about the fitted model, run  <code>tensorboard --logdir=logs</code> from the command line interface.</li> </ul>"}]}